{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "['tx_hash', 'coinbase', 'block_hash', 'height', 'timestamp', 'id', 'value', 'script_type', 'output_address', 'input_address', 'year', 'month', 'day', 'close-price']\n"
     ]
    }
   ],
   "source": [
    "#IMPORT\n",
    "try:\n",
    "    import graphlab as gl\n",
    "    import numpy as np\n",
    "    import graphlab.aggregate as agg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import rcParams\n",
    "    import datetime as dt   \n",
    "    from graphlab import degree_counting\n",
    "    from graphlab import connected_components\n",
    "    from graphlab import pagerank\n",
    "    from graphlab import shortest_path\n",
    "    from graphlab import triangle_counting\n",
    "    from graphlab import label_propagation\n",
    "    from graphlab import kcore\n",
    "    from graphlab import graph_coloring\n",
    "    import os\n",
    "    print('success')\n",
    "except:\n",
    "    raise ImportError(\"Key libraries cannot be loaded.\")\n",
    "\n",
    "\n",
    "transaction_data = '../code/graph-code/data/blocks_417500_424572/'\n",
    "\n",
    "if os.path.exists('../code/graph-code/data/blocks_417500_424572'):\n",
    "    sf = gl.SFrame(transaction_data)\n",
    "    # TAKE SAMPLE\n",
    "    s = sf.sample(0.00001, seed=1)\n",
    "    df = s.to_dataframe()\n",
    "    df = df[df['input_address'].notnull()]\n",
    "    df = df[df['output_address'].notnull()]\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    sf = gl.SFrame(df)\n",
    "\n",
    "    print(sf.column_names())\n",
    "else:\n",
    "    print('cant find data')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  Tag\n",
      "0  111    1\n",
      "1  222    2\n",
      "2  111    3\n",
      "3  444    1\n",
      "4  222    2\n",
      "5  111    1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "d = {'ID' : pd.Series([111, 222, 111, 444, 222, 111]), 'Tag' : pd.Series([1, 2, 3, 1, 2, 1])}\n",
    "df1 = (pd.DataFrame(d))\n",
    "print(df1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID\n",
      "0  111\n",
      "1  444\n",
      "2  666\n",
      "3  444\n",
      "4  777\n"
     ]
    }
   ],
   "source": [
    "d = {'ID' : pd.Series([111, 444, 666, 444, 777])}\n",
    "df2 = (pd.DataFrame(d))\n",
    "print(df2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  tag1  tag2  tag3\n",
      "0  111     2     0     1\n",
      "1  444     1     0     0\n",
      "2  666     0     0     0\n",
      "3  444     1     0     0\n",
      "4  777     0     0     0\n"
     ]
    }
   ],
   "source": [
    "df2['tag1'] = 0\n",
    "df2['tag2'] = 0\n",
    "df2['tag3'] = 0\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    for i, t in df1.iterrows():\n",
    "        if row['ID'] == t['ID']:\n",
    "            if t['Tag'] == 1:\n",
    "                df2.loc[index][\"tag1\"] += 1\n",
    "            elif t['Tag'] == 2:\n",
    "                df2.loc[index][\"tag2\"] += 1\n",
    "            elif t['Tag'] == 3:\n",
    "                df2.loc[index][\"tag3\"] += 1\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  tag1_x  tag2_x  tag3_x  tag1_y  tag2_y  tag3_y\n",
      "0  111       2       0       1       2       0       1\n",
      "1  444       1       0       0       1       0       0\n",
      "2  666       0       0       0       0       0       0\n",
      "3  444       1       0       0       1       0       0\n",
      "4  777       0       0       0       0       0       0\n"
     ]
    }
   ],
   "source": [
    "print (pd.merge(df2, pd.crosstab(df1.ID, df1.Tag)\n",
    "                       .add_prefix('tag')\n",
    "                       .reset_index(), on='ID', how='left')\n",
    "         .fillna(0)\n",
    "         .astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  X1  X2  X3 Merged_Tags\n",
      "0   0   1   1   0         NaN\n",
      "1   2   1   2   2       [Two]\n",
      "2   1   2   0   0  [One, Two]\n",
      "3   1   0   1   1  [One, Two]\n",
      "4   0   0   0   1         NaN\n"
     ]
    }
   ],
   "source": [
    "df1['Merged_Tags'] = df1.ID.map(df2.groupby('ID').Tag.apply(list))\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Hash   X1   X2   X3\n",
      "0   1HYKGGzRHDskth2ecKZ2HYvxSvQ1p87m6  111  111  111\n",
      "1  3DndG5HuyP8Ep8p3V1i394AUxG4gtgsvoj  222  222  222\n",
      "2   1HYKGGzRHDskth2ecKZ2HYvxSvQ1p87m6  333  333  333\n"
     ]
    }
   ],
   "source": [
    "d = {'Hash' : pd.Series(['1HYKGGzRHDskth2ecKZ2HYvxSvQ1p87m6', '3DndG5HuyP8Ep8p3V1i394AUxG4gtgsvoj', '1HYKGGzRHDskth2ecKZ2HYvxSvQ1p87m6']), \n",
    "     'X1' : pd.Series([111, 222, 333]),\n",
    "     'X2' : pd.Series([111, 222, 333]),\n",
    "     'X3' : pd.Series([111, 222, 333])\n",
    "    }\n",
    "                                                                                                                        \n",
    "df1 = (pd.DataFrame(d))\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Hash   X1   X2   X3  via_categ\n",
      "0   1HYKGGzRHDskth2ecKZ2HYvxSvQ1p87m6  111  111  111          1\n",
      "1  3DndG5HuyP8Ep8p3V1i394AUxG4gtgsvoj  222  222  222          2\n",
      "2   1HYKGGzRHDskth2ecKZ2HYvxSvQ1p87m6  333  333  333          1\n"
     ]
    }
   ],
   "source": [
    "# #REPLACE HASH WITH INT\n",
    "# look_up = {}\n",
    "# count = 0\n",
    "# for index, row in df1.iterrows():\n",
    "#     count +=1\n",
    "#     if row['Hash'] not in look_up:\n",
    "#         look_up[row['Hash']] = count\n",
    "#     else:\n",
    "#         continue\n",
    "# print(look_up)\n",
    "\n",
    "df1[\"via_categ\"] = pd.Categorical(df1.Hash).codes + 1\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for index, row in df1.iterrows():\n",
    "#     for address, id_int in look_up.iteritems():\n",
    "#         if address == row['Hash']:            \n",
    "#             df1.set_value(index, row['Hash'], id_int)\n",
    "# print(df1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID   X1   X2   X3\n",
      "0   1  111  111  111\n",
      "1   2  222  222  222\n",
      "2   1  333  333  333\n"
     ]
    }
   ],
   "source": [
    "d = {'ID' : pd.Series([1, 2, 1]), \n",
    "     'X1' : pd.Series([111, 222, 333]),\n",
    "     'X2' : pd.Series([111, 222, 333]),\n",
    "     'X3' : pd.Series([111, 222, 333])\n",
    "    }\n",
    "                                                                                                                        \n",
    "df3 = (pd.DataFrame(d))\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID   X1      X2   X3\n",
      "0   1  111  [0, 1]  111\n",
      "1   2  222  [1, 2]  222\n",
      "2   1  333  [2, 4]  333\n"
     ]
    }
   ],
   "source": [
    "import sklearn.cluster\n",
    "import numpy as np\n",
    "\n",
    "d = {'ID' : pd.Series([1, 2, 1]), \n",
    "     'X1' : pd.Series([111, 222, 333]),\n",
    "     'X2' : pd.Series([[0,1], [1,2], [2,4]]),\n",
    "     'X3' : pd.Series([111, 222, 333])\n",
    "    }\n",
    "                                                                                                                        \n",
    "df1 = (pd.DataFrame(d))\n",
    "\n",
    "labels = []\n",
    "for index, row in df1.iterrows():\n",
    "    labels.append(row['ID'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-90ce8f560627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclust_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclust_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/btc-env/lib/python2.7/site-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, return_n_iter)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mbest_inertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/btc-env/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mas_float_array\u001b[0;34m(X, copy, force_all_finite)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F_CONTIGUOUS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: D"
     ]
    }
   ],
   "source": [
    "features = np.array([x[1:] for x in df1])\n",
    "\n",
    "clust_centers = 2\n",
    "model = sklearn.cluster.k_means(features, clust_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [gl-env]",
   "language": "python",
   "name": "Python [gl-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
